        sasl.oauthbearer.sub.claim.name = sub
        sasl.oauthbearer.token.endpoint.url = null
        security.protocol = PLAINTEXT
        security.providers = null
        send.buffer.bytes = 131072
        socket.connection.setup.timeout.max.ms = 30000
        socket.connection.setup.timeout.ms = 10000
        ssl.cipher.suites = null
        ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
        ssl.endpoint.identification.algorithm = https
        ssl.engine.factory.class = null
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.certificate.chain = null
        ssl.keystore.key = null
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLSv1.3
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.certificates = null
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig)
[2024-06-06 03:16:42,282] WARN These configurations '[compression.type, confluent.metrics.reporter.bootstrap.servers, enable.idempotence, acks, key.serializer, max.request.size, value.serializer, interceptor.classes, max.in.flight.requests.per.connection, linger.ms]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
[2024-06-06 03:16:42,283] INFO Kafka version: 7.4.0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:16:42,293] INFO Kafka commitId: cc2964509eb513f9fcd13f7d8d80bba29fedc13a (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:16:42,293] INFO Kafka startTimeMs: 1717643802283 (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:16:43,437] INFO Creating topic _confluent-telemetry-metrics with configuration {max.message.bytes=10485760, message.timestamp.type=CreateTime, min.insync.replicas=1, retention.ms=259200000, segment.ms=14400000, retention.bytes=-1} and initial partition assignment HashMap(0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 2 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 3 -> 
ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 5 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 8 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 11 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient) 
[2024-06-06 03:16:43,778] INFO Waiting for 60 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2024-06-06 03:16:44,293] INFO [Controller id=1] New topics: [Set(_confluent-telemetry-metrics)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(_confluent-telemetry-metrics,Some(iVwfKPw2TtSI9mQl5FoK_g),None,HashMap(_confluent-telemetry-metrics-5 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-11 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-8 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-3 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-2 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None), _confluent-telemetry-metrics-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=, observers=, targetObservers=None)),None))] (kafka.controller.KafkaController)
[2024-06-06 03:16:44,318] INFO [Controller id=1] New partition creation callback for _confluent-telemetry-metrics-5,_confluent-telemetry-metrics-10,_confluent-telemetry-metrics-4,_confluent-telemetry-metrics-7,_confluent-telemetry-metrics-11,_confluent-telemetry-metrics-8,_confluent-telemetry-metrics-6,_confluent-telemetry-metrics-3,_confluent-telemetry-metrics-0,_confluent-telemetry-metrics-9,_confluent-telemetry-metrics-2,_confluent-telemetry-metrics-1 (kafka.controller.KafkaController)
[2024-06-06 03:16:44,319] INFO [PartitionStateMachine controllerId=1] Attempting to transition 12 partitions to NewPartition with election strategy None (kafka.controller.ZkPartitionStateMachine)
[2024-06-06 03:16:44,320] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-5 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-10 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-4 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-7 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-11 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-8 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-6 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,321] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-3 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,322] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-0 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,322] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-9 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,322] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-2 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,323] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-1 from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2024-06-06 03:16:44,336] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-6 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,337] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-5 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,337] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-4 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,337] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-8 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-11 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-7 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-1 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-10 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-3 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,338] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-2 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,339] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-9 from NonExistentReplica to NewReplica (state.change.logger)
[2024-06-06 03:16:44,339] INFO [PartitionStateMachine controllerId=1] Attempting to transition 12 partitions to OnlinePartition with election strategy Some(OfflinePartitionLeaderElectionStrategy(false)) (kafka.controller.ZkPartitionStateMachine)
[2024-06-06 03:16:45,653] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,654] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,655] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,656] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,656] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,669] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,670] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,670] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,671] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,671] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,672] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,673] INFO [Controller id=1 epoch=1] Changed partition _confluent-telemetry-metrics-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
[2024-06-06 03:16:45,688] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=3, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-3 (state.change.logger)
[2024-06-06 03:16:45,692] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=4, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-4 (state.change.logger)
[2024-06-06 03:16:45,693] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-6 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,695] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=5, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-5 (state.change.logger)
[2024-06-06 03:16:45,707] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-5 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,712] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-4 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,712] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=6, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-6 (state.change.logger)
[2024-06-06 03:16:45,715] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=7, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-7 (state.change.logger)
[2024-06-06 03:16:45,716] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=8, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-8 (state.change.logger)
[2024-06-06 03:16:45,716] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=9, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-9 (state.change.logger)
[2024-06-06 03:16:45,712] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-8 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,725] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=10, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-10 (state.change.logger)
[2024-06-06 03:16:45,728] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,733] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=11, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-11 (state.change.logger)
[2024-06-06 03:16:45,733] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-11 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,742] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-7 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,742] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-1 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,743] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-10 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,744] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-3 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,744] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-2 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,744] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-telemetry-metrics-9 from NewReplica to OnlineReplica (state.change.logger)
[2024-06-06 03:16:45,743] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=0, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-0 (state.change.logger)
[2024-06-06 03:16:45,772] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=1, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-1 (state.change.logger)
[2024-06-06 03:16:45,773] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=2, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition _confluent-telemetry-metrics-2 (state.change.logger)
[2024-06-06 03:16:45,774] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 12 become-leader and 0 become-follower partitions (state.change.logger)
[2024-06-06 03:16:45,781] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 for 12 partitions (state.change.logger)
[2024-06-06 03:16:45,786] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=3, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,787] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=4, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,787] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=5, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,788] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=6, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,792] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=7, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,793] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=8, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,793] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=9, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,793] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=10, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,794] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=11, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,794] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=0, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,795] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=1, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,795] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='_confluent-telemetry-metrics', topicId=iVwfKPw2TtSI9mQl5FoK_g, clusterLinkId=null, clusterLinkTopicState=null, linkedLeaderEpoch=-1, clusterLinkSourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, partitionIndex=2, controllerEpoch=1, leader=1, confluentIsUncleanLeader=false, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], observers=[], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 1 (state.change.logger)
[2024-06-06 03:16:45,796] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-3 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:45,881] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-4 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:45,925] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-5 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:45,994] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-6 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,051] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-7 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,119] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-8 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,163] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-9 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,210] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-10 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,253] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-11 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,281] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-0 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,331] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-1 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,358] INFO [Broker id=1] Received LeaderAndISR request for a stray partition: _confluent-telemetry-metrics-2 that does not constitute a misclassification. (state.change.logger)
[2024-06-06 03:16:46,394] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-11 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-9 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-7 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-5 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-3 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-1 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-10 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-8 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-6 (state.change.logger)
[2024-06-06 03:16:46,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-4 (state.change.logger)
[2024-06-06 03:16:46,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-2 (state.change.logger)
[2024-06-06 03:16:46,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-telemetry-metrics-0 (state.change.logger)
[2024-06-06 03:16:46,397] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(_confluent-telemetry-metrics-5, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-11, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-1) (kafka.server.ReplicaFetcherManager)
[2024-06-06 03:16:46,416] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 1 epoch 1 as part of the become-leader transition for 12 partitions (state.change.logger)
[2024-06-06 03:16:46,578] INFO [MergedLog partition=_confluent-telemetry-metrics-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:46,881] INFO Created log for partition _confluent-telemetry-metrics-11 in /var/lib/kafka/data/_confluent-telemetry-metrics-11 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:46,884] INFO [Partition _confluent-telemetry-metrics-11 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-11 (kafka.cluster.Partition)
[2024-06-06 03:16:46,938] INFO [Partition _confluent-telemetry-metrics-11 broker=1] Log loaded for partition _confluent-telemetry-metrics-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:46,939] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-11 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:46,973] INFO [MergedLog partition=_confluent-telemetry-metrics-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)[2024-06-06 03:16:46,978] INFO [Broker id=1] Leader _confluent-telemetry-metrics-11 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:47,084] INFO [MergedLog partition=_confluent-telemetry-metrics-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:47,144] INFO Created log for partition _confluent-telemetry-metrics-9 in /var/lib/kafka/data/_confluent-telemetry-metrics-9 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:47,156] INFO [Partition _confluent-telemetry-metrics-9 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-9 (kafka.cluster.Partition)
[2024-06-06 03:16:47,157] INFO [Partition _confluent-telemetry-metrics-9 broker=1] Log loaded for partition _confluent-telemetry-metrics-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:47,159] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-9 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:47,160] INFO [MergedLog partition=_confluent-telemetry-metrics-9, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-9 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:47,161] INFO [Broker id=1] Leader _confluent-telemetry-metrics-9 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:47,325] INFO [MergedLog partition=_confluent-telemetry-metrics-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:47,345] INFO Created log for partition _confluent-telemetry-metrics-7 in /var/lib/kafka/data/_confluent-telemetry-metrics-7 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:47,346] INFO [Partition _confluent-telemetry-metrics-7 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-7 (kafka.cluster.Partition)
[2024-06-06 03:16:47,358] INFO [Partition _confluent-telemetry-metrics-7 broker=1] Log loaded for partition _confluent-telemetry-metrics-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:47,360] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-7 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:47,373] INFO [MergedLog partition=_confluent-telemetry-metrics-7, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-7 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:47,375] INFO [Broker id=1] Leader _confluent-telemetry-metrics-7 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:47,457] INFO [MergedLog partition=_confluent-telemetry-metrics-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:47,484] INFO Created log for partition _confluent-telemetry-metrics-5 in /var/lib/kafka/data/_confluent-telemetry-metrics-5 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:47,485] INFO [Partition _confluent-telemetry-metrics-5 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-5 (kafka.cluster.Partition)
[2024-06-06 03:16:47,486] INFO [Partition _confluent-telemetry-metrics-5 broker=1] Log loaded for partition _confluent-telemetry-metrics-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:47,487] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-5 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:47,498] INFO [MergedLog partition=_confluent-telemetry-metrics-5, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-5 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:47,499] INFO [Broker id=1] Leader _confluent-telemetry-metrics-5 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:47,635] INFO [MergedLog partition=_confluent-telemetry-metrics-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:47,667] INFO Created log for partition _confluent-telemetry-metrics-3 in /var/lib/kafka/data/_confluent-telemetry-metrics-3 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:47,670] INFO [Partition _confluent-telemetry-metrics-3 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-3 (kafka.cluster.Partition)
[2024-06-06 03:16:47,673] INFO [Partition _confluent-telemetry-metrics-3 broker=1] Log loaded for partition _confluent-telemetry-metrics-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:47,720] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-3 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:47,722] INFO [MergedLog partition=_confluent-telemetry-metrics-3, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-3 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:47,723] INFO [Broker id=1] Leader _confluent-telemetry-metrics-3 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:47,841] INFO [MergedLog partition=_confluent-telemetry-metrics-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:47,860] INFO Created log for partition _confluent-telemetry-metrics-1 in /var/lib/kafka/data/_confluent-telemetry-metrics-1 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:47,865] INFO [Partition _confluent-telemetry-metrics-1 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-1 (kafka.cluster.Partition)
[2024-06-06 03:16:47,866] INFO [Partition _confluent-telemetry-metrics-1 broker=1] Log loaded for partition _confluent-telemetry-metrics-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:47,867] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-1 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:47,868] INFO [MergedLog partition=_confluent-telemetry-metrics-1, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-1 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:47,869] INFO [Broker id=1] Leader _confluent-telemetry-metrics-1 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:48,011] INFO [MergedLog partition=_confluent-telemetry-metrics-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:48,044] INFO Created log for partition _confluent-telemetry-metrics-10 in /var/lib/kafka/data/_confluent-telemetry-metrics-10 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:48,045] INFO [Partition _confluent-telemetry-metrics-10 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-10 (kafka.cluster.Partition)
[2024-06-06 03:16:48,046] INFO [Partition _confluent-telemetry-metrics-10 broker=1] Log loaded for partition _confluent-telemetry-metrics-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:48,047] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-10 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:48,048] INFO [MergedLog partition=_confluent-telemetry-metrics-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)[2024-06-06 03:16:48,049] INFO [Broker id=1] Leader _confluent-telemetry-metrics-10 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:48,132] INFO [MergedLog partition=_confluent-telemetry-metrics-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:48,152] INFO Created log for partition _confluent-telemetry-metrics-8 in /var/lib/kafka/data/_confluent-telemetry-metrics-8 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:48,166] INFO [Partition _confluent-telemetry-metrics-8 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-8 (kafka.cluster.Partition)
[2024-06-06 03:16:48,167] INFO [Partition _confluent-telemetry-metrics-8 broker=1] Log loaded for partition _confluent-telemetry-metrics-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:48,168] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-8 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:48,169] INFO [MergedLog partition=_confluent-telemetry-metrics-8, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-8 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:48,169] INFO [Broker id=1] Leader _confluent-telemetry-metrics-8 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:48,401] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:48,434] INFO Created log for partition _confluent-telemetry-metrics-6 in /var/lib/kafka/data/_confluent-telemetry-metrics-6 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:48,434] INFO [Partition _confluent-telemetry-metrics-6 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-6 (kafka.cluster.Partition)
[2024-06-06 03:16:48,435] INFO [Partition _confluent-telemetry-metrics-6 broker=1] Log loaded for partition _confluent-telemetry-metrics-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:48,447] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-6 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:48,448] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-6 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:48,449] INFO [Broker id=1] Leader _confluent-telemetry-metrics-6 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:48,590] INFO [MergedLog partition=_confluent-telemetry-metrics-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:48,609] INFO Created log for partition _confluent-telemetry-metrics-4 in /var/lib/kafka/data/_confluent-telemetry-metrics-4 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:48,609] INFO [Partition _confluent-telemetry-metrics-4 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-4 (kafka.cluster.Partition)
[2024-06-06 03:16:48,648] INFO [Partition _confluent-telemetry-metrics-4 broker=1] Log loaded for partition _confluent-telemetry-metrics-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:48,649] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-4 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:48,650] INFO [MergedLog partition=_confluent-telemetry-metrics-4, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-4 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:48,664] INFO [Broker id=1] Leader _confluent-telemetry-metrics-4 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:48,813] INFO [MergedLog partition=_confluent-telemetry-metrics-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:48,844] INFO Created log for partition _confluent-telemetry-metrics-2 in /var/lib/kafka/data/_confluent-telemetry-metrics-2 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:48,845] INFO [Partition _confluent-telemetry-metrics-2 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-2 (kafka.cluster.Partition)
[2024-06-06 03:16:48,846] INFO [Partition _confluent-telemetry-metrics-2 broker=1] Log loaded for partition _confluent-telemetry-metrics-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:48,859] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-2 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:48,861] INFO [MergedLog partition=_confluent-telemetry-metrics-2, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-2 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:48,862] INFO [Broker id=1] Leader _confluent-telemetry-metrics-2 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:49,009] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.MergedLog$)
[2024-06-06 03:16:49,042] INFO Created log for partition _confluent-telemetry-metrics-0 in /var/lib/kafka/data/_confluent-telemetry-metrics-0 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2024-06-06 03:16:49,043] INFO [Partition _confluent-telemetry-metrics-0 broker=1] No checkpointed highwatermark is found 
for partition _confluent-telemetry-metrics-0 (kafka.cluster.Partition)
[2024-06-06 03:16:49,043] INFO [Partition _confluent-telemetry-metrics-0 broker=1] Log loaded for partition _confluent-telemetry-metrics-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-06-06 03:16:49,044] INFO Setting topicIdPartition iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-0 (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:16:49,057] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Initializing 
tier metadata without recovery for _confluent-telemetry-metrics-0 because, either the recovery is active (false) or local 
log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)  
[2024-06-06 03:16:49,057] INFO [Broker id=1] Leader _confluent-telemetry-metrics-0 with topic id Some(iVwfKPw2TtSI9mQl5FoK_g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [], and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-11 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-9 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-7 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-5 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-3 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-1 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-10 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-8 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-6 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-4 (state.change.logger)
[2024-06-06 03:16:49,059] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-2 (state.change.logger)
[2024-06-06 03:16:49,060] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition _confluent-telemetry-metrics-0 (state.change.logger)
[2024-06-06 03:16:49,074] INFO [Broker id=1] Finished LeaderAndIsr request in 3294ms correlationId 5 from controller 1 for 12 partitions (state.change.logger)
[2024-06-06 03:16:49,096] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=iVwfKPw2TtSI9mQl5FoK_g, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 5 sent to broker broker:29092 (id: 1 rack: null tags: []) (state.change.logger)
[2024-06-06 03:16:49,111] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to broker 1 for 12 partitions (state.change.logger)
[2024-06-06 03:16:49,149] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,183] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,184] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,184] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,185] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,185] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,185] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,186] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,186] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,186] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,215] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,215] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='_confluent-telemetry-metrics', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], observers=[], offlineReplicas=[]) for partition _confluent-telemetry-metrics-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,216] INFO [Broker id=1] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2024-06-06 03:16:49,321] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 6 sent to broker broker:29092 (id: 1 rack: null tags: []) (state.change.logger) 
[2024-06-06 03:16:49,357] INFO Created telemetry topic _confluent-telemetry-metrics (io.confluent.telemetry.exporter.kafka.KafkaExporter)
[2024-06-06 03:16:49,360] INFO App info kafka.admin.client for confluent-telemetry-reporter-local-producer unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:16:49,407] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:16:49,407] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:16:49,408] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:16:49,727] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-0 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,728] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-5 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,729] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-10 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,729] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-8 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,730] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-2 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,742] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-9 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,742] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-11 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,743] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-4 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,743] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-1 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,743] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-6 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,743] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-7 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:16:49,743] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Resetting the last seen epoch of partition _confluent-telemetry-metrics-3 to 0 since the associated topicId changed from null to iVwfKPw2TtSI9mQl5FoK_g (org.apache.kafka.clients.Metadata)
[2024-06-06 03:17:27,090] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-06-06 03:17:27,106] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-06-06 03:17:27,123] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-06-06 03:17:27,330] INFO Stopped NetworkTrafficServerConnector@68c4a860{HTTP/1.1, (http/1.1, h2c)}{0.0.0.0:8090} (org.eclipse.jetty.server.AbstractConnector)
[2024-06-06 03:17:27,331] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2024-06-06 03:17:27,402] INFO Stopped o.e.j.s.ServletContextHandler@572eb1d5{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2024-06-06 03:17:27,403] INFO Stopped o.e.j.s.ServletContextHandler@67bfad6f{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2024-06-06 03:17:27,435] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
[2024-06-06 03:17:27,438] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
[2024-06-06 03:17:27,466] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
[2024-06-06 03:17:27,478] DEBUG [Controller id=1] Controller received controlled shutdown request from broker 1 due to reason: UNKNOWN (kafka.controller.KafkaController)
[2024-06-06 03:17:27,985] TRACE [Controller id=1] All leaders = _confluent-telemetry-metrics-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-command-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-metrics-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),_confluent-telemetry-metrics-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
[2024-06-06 03:17:28,068] INFO Stopped o.e.j.s.ServletContextHandler@299e2c87{/kafka,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2024-06-06 03:17:28,095] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 684ms (kafka.server.KafkaServer)
[2024-06-06 03:17:28,154] INFO Stopped o.e.j.s.ServletContextHandler@54bc533f{/v1/metadata,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2024-06-06 03:17:28,264] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,265] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,267] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,299] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,301] INFO Closing reporter io.confluent.telemetry.reporter.TelemetryReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,302] INFO Stopping TelemetryReporter collectorTask (io.confluent.telemetry.reporter.TelemetryReporter)
[2024-06-06 03:17:28,308] INFO Closing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
[2024-06-06 03:17:28,512] INFO Closing License Store (io.confluent.license.LicenseStore)
[2024-06-06 03:17:28,515] INFO Stopping KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2024-06-06 03:17:28,526] INFO [Producer clientId=_confluent-license-producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[2024-06-06 03:17:28,558] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,558] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,559] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,560] INFO App info kafka.producer for _confluent-license-producer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:17:28,561] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,562] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,562] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,582] INFO App info kafka.consumer for _confluent-license-consumer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-06-06 03:17:28,583] INFO Stopped KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2024-06-06 03:17:28,583] INFO Closed License Store (io.confluent.license.LicenseStore)
[2024-06-06 03:17:28,647] INFO KafkaHttpServer transitioned from RUNNING to STOPPING.. (io.confluent.http.server.KafkaHttpServerImpl)
[2024-06-06 03:17:28,742] INFO Stopping TelemetryReporter remoteConfigTask (io.confluent.telemetry.reporter.TelemetryReporter)
[2024-06-06 03:17:28,853] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,865] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-06-06 03:17:28,867] INFO KafkaHttpServer transitioned from STOPPING to TERMINATED.. (io.confluent.http.server.KafkaHttpServerImpl)
[2024-06-06 03:17:28,918] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-06-06 03:17:28,931] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-06-06 03:17:28,932] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-06-06 03:17:28,954] INFO Broker Load Metric closed. (kafka.metrics.BrokerLoad)
[2024-06-06 03:17:28,978] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2024-06-06 03:17:29,045] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,045] INFO [Producer clientId=confluent-metrics-reporter] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,103] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,115] INFO [Producer clientId=confluent-metrics-reporter] Cancelled in-flight METADATA request with correlation id 23 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request 
timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,178] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,191] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:29,206] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,625] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,626] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,695] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:29,709] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:30,133] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,134] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,149] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2024-06-06 03:17:30,169] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-06-06 03:17:30,204] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,204] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:30,263] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-06-06 03:17:30,335] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,357] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,359] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,368] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2024-06-06 03:17:30,442] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,516] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,516] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:30,620] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-06-06 03:17:30,639] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,641] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,710] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:30,711] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:30,787] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-06-06 03:17:30,788] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-06-06 03:17:30,801] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-06-06 03:17:30,801] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-06-06 03:17:30,857] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-06-06 03:17:30,974] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-06-06 03:17:31,157] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,188] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:31,188] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:31,196] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,196] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,198] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,225] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,228] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,233] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)        
[2024-06-06 03:17:31,486] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:31,487] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:31,727] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2024-06-06 03:17:31,777] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)   
[2024-06-06 03:17:31,836] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-06-06 03:17:31,837] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-06-06 03:17:31,842] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)     
[2024-06-06 03:17:31,888] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)[2024-06-06 03:17:31,891] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-06-06 03:17:31,904] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-06-06 03:17:31,905] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,906] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,906] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,969] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,983] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:31,983] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,003] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,009] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,009] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,014] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,022] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,022] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,035] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:32,036] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:32,036] INFO [ExpirationReaper-1-ListOffsets]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,046] INFO [ExpirationReaper-1-ListOffsets]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,046] INFO [ExpirationReaper-1-ListOffsets]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,241] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2024-06-06 03:17:32,258] INFO [ClusterLinkManager-broker-1] Shutting down (kafka.server.link.ClusterLinkManager)
[2024-06-06 03:17:32,333] INFO [ExpirationReaper-1-ClusterLink]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,358] INFO [ExpirationReaper-1-ClusterLink]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,358] INFO [ExpirationReaper-1-ClusterLink]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-06-06 03:17:32,441] INFO [ClusterLinkManager-broker-1] Shutdown completed (kafka.server.link.ClusterLinkManager)    
[2024-06-06 03:17:32,456] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,457] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,457] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,505] INFO Broker to controller channel manager for alterPartition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2024-06-06 03:17:32,509] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:32,509] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,509] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:32,510] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,510] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2024-06-06 03:17:32,548] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2024-06-06 03:17:32,552] INFO Shutting down. (kafka.log.LogManager)
[2024-06-06 03:17:32,588] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
[2024-06-06 03:17:32,601] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner)
[2024-06-06 03:17:32,605] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner)
[2024-06-06 03:17:32,605] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner)
[2024-06-06 03:17:33,107] INFO Tier partition state for fZIpzbYYRQSVhpFQ0spQ1Q:_confluent-metrics-10 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:33,163] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:33,164] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:33,261] INFO [ProducerStateManager partition=_confluent-metrics-10] Wrote producer snapshot at offset 2 
with 0 producer ids in 78 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:33,335] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:33,336] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:34,168] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:34,169] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:34,436] INFO Closing log for _confluent-metrics-10 took 1726 ms. (kafka.log.LogManager)
[2024-06-06 03:17:34,493] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:34,493] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:34,647] INFO Tier partition state for iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-10 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:34,650] INFO [ProducerStateManager partition=_confluent-telemetry-metrics-10] Wrote producer snapshot at offset 96 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:34,785] INFO Closing log for _confluent-telemetry-metrics-10 took 348 ms. (kafka.log.LogManager)        
[2024-06-06 03:17:35,013] INFO Tier partition state for iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-1 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:35,015] INFO [ProducerStateManager partition=_confluent-telemetry-metrics-1] Wrote producer snapshot at 
offset 36 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:35,118] INFO Closing log for _confluent-telemetry-metrics-1 took 325 ms. (kafka.log.LogManager)
[2024-06-06 03:17:35,264] INFO Tier partition state for fZIpzbYYRQSVhpFQ0spQ1Q:_confluent-metrics-2 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:35,279] INFO Closing log for _confluent-metrics-2 took 160 ms. (kafka.log.LogManager)
[2024-06-06 03:17:35,363] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:35,363] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:35,617] INFO Tier partition state for fZIpzbYYRQSVhpFQ0spQ1Q:_confluent-metrics-5 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:35,626] INFO [ProducerStateManager partition=_confluent-metrics-5] Wrote producer snapshot at offset 2 with 0 producer ids in 7 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:35,687] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:35,688] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:35,702] INFO Closing log for _confluent-metrics-5 took 422 ms. (kafka.log.LogManager)
[2024-06-06 03:17:36,216] INFO Tier partition state for fZIpzbYYRQSVhpFQ0spQ1Q:_confluent-metrics-7 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:36,219] INFO [ProducerStateManager partition=_confluent-metrics-7] Wrote producer snapshot at offset 4 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:36,331] INFO Closing log for _confluent-metrics-7 took 629 ms. (kafka.log.LogManager)
[2024-06-06 03:17:36,349] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:36,349] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:36,621] INFO Tier partition state for iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-8 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:36,623] INFO [ProducerStateManager partition=_confluent-telemetry-metrics-8] Wrote producer snapshot at 
offset 77 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2024-06-06 03:17:36,788] INFO Closing log for _confluent-telemetry-metrics-8 took 456 ms. (kafka.log.LogManager)
[2024-06-06 03:17:36,814] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:36,815] WARN [Producer clientId=confluent-telemetry-reporter-local-producer] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)       
[2024-06-06 03:17:36,915] INFO Tier partition state for fZIpzbYYRQSVhpFQ0spQ1Q:_confluent-metrics-1 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:36,921] INFO Closing log for _confluent-metrics-1 took 132 ms. (kafka.log.LogManager)
[2024-06-06 03:17:37,020] INFO Tier partition state for iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-6 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:37,025] INFO Closing log for _confluent-telemetry-metrics-6 took 104 ms. (kafka.log.LogManager)
[2024-06-06 03:17:37,102] INFO Tier partition state for iVwfKPw2TtSI9mQl5FoK_g:_confluent-telemetry-metrics-4 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:37,110] INFO Closing log for _confluent-telemetry-metrics-4 took 84 ms. (kafka.log.LogManager)
[2024-06-06 03:17:37,199] INFO Tier partition state for 0E9H3b5qSP2RfS4aHbdNAQ:_confluent-command-0 closed. (kafka.tier.state.FileTierPartitionState)
[2024-06-06 03:17:37,209] INFO Closing log for _confluent-command-0 took 98 ms. (kafka.log.LogManager)
[2024-06-06 03:17:37,216] INFO [Producer clientId=confluent-metrics-reporter] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-06-06 03:17:37,216] WARN [Producer clientId=confluent-metrics-reporter] Connection to node 1 (broker/172.19.0.5:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)